{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bild einlesen\n",
    "img = cv2.imread('Utils/links-muster-3.png')\n",
    "\n",
    "# Bild in Graustufen umwandeln\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Kanten mit dem Canny-Algorithmus detektieren\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "# Kanten anzeigen\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(121), plt.imshow(gray, cmap='gray')\n",
    "plt.title('Graustufenbild'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(edges, cmap='gray')\n",
    "plt.title('Kantendetektion'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bild einlesen\n",
    "img = cv2.imread('Utils/links-muster-3.png')\n",
    "# Bild in Graustufen umwandeln\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Prewitt-Filter definieren\n",
    "prewitt_kernel_x = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])\n",
    "prewitt_kernel_y = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])\n",
    "\n",
    "# Filter anwenden\n",
    "grad_x = cv2.filter2D(gray, cv2.CV_64F, prewitt_kernel_x)\n",
    "grad_y = cv2.filter2D(gray, cv2.CV_64F, prewitt_kernel_y)\n",
    "\n",
    "# Gradientenbilder kombinieren\n",
    "magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "magnitude = cv2.convertScaleAbs(magnitude)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(131), plt.imshow(gray, cmap='gray')\n",
    "plt.title('Graustufenbild'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132), plt.imshow(grad_x, cmap='gray')\n",
    "plt.title('Prewitt X'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133), plt.imshow(grad_y, cmap='gray')\n",
    "plt.title('Prewitt Y'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(magnitude, cmap='gray')\n",
    "plt.title('Prewitt-Kantendetektion'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ],
   "id": "22e2e4033850fb97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bild einlesen\n",
    "img = cv2.imread('Utils/links-muster-3.png')\n",
    "\n",
    "# Überprüfen, ob das Bild korrekt eingelesen wurde\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"Das Bild konnte nicht geladen werden. Bitte überprüfen Sie den Pfad.\")\n",
    "\n",
    "# Bild in Graustufen umwandeln\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Prewitt-Filter für horizontale Richtung definieren\n",
    "prewitt_kernel_x = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])\n",
    "\n",
    "# Horizontalen Prewitt-Filter anwenden\n",
    "grad_x = cv2.filter2D(gray, cv2.CV_64F, prewitt_kernel_x)\n",
    "\n",
    "# Betrag der horizontalen Gradienten berechnen\n",
    "abs_grad_x = np.abs(grad_x)\n",
    "\n",
    "# Optional: Ausgabe als Bild zur Überprüfung\n",
    "abs_grad_x_img = cv2.convertScaleAbs(abs_grad_x)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121), plt.imshow(gray, cmap='gray')\n",
    "plt.title('Graustufenbild'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(abs_grad_x_img, cmap='gray')\n",
    "plt.title('Horizontale Gradienten (Prewitt X)'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "\n",
    "# Horizontale Gradienten als numerische Werte ausgeben\n",
    "print(\"Horizontale Gradienten (Prewitt X):\")\n",
    "print(abs_grad_x)\n",
    "\n",
    "# Beispiel: Durchschnittliche Änderung pro Zeile\n",
    "average_change_per_row = np.mean(abs_grad_x, axis=1)\n",
    "print(\"\\nDurchschnittliche horizontale Änderung pro Zeile:\")\n",
    "print(average_change_per_row)\n",
    "\n",
    "# Beispiel: Durchschnittliche Änderung pro Spalte\n",
    "average_change_per_column = np.mean(abs_grad_x, axis=0)\n",
    "print(\"\\nDurchschnittliche horizontale Änderung pro Spalte:\")\n",
    "print(average_change_per_column)\n",
    "plt.show()"
   ],
   "id": "6c9e6f92338dc2b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Laden der aufgenommenen Bilder (linke und rechte Ansicht)\n",
    "imgL = cv2.imread('Utils/lasertestv2-links.png', cv2.IMREAD_GRAYSCALE)\n",
    "imgR = cv2.imread('Utils/lasertestv2-rechts.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Laden des Gittermusters (Pattern), das auf die Szene projiziert wurde\n",
    "pattern = cv2.imread('Utils/lasertestv2-links2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def undistort_pattern(img, pattern):\n",
    "    # Annahme: Das Gittermuster wurde nur in der horizontalen oder vertikalen Richtung verzerrt.\n",
    "    \n",
    "    # Find corners in pattern\n",
    "    ret, corners_pattern = cv2.findChessboardCorners(pattern, (9, 6), None)\n",
    "    \n",
    "    if not ret:\n",
    "        raise ValueError(\"Gittermuster konnte nicht gefunden werden.\")\n",
    "    \n",
    "    # Find corners in input image\n",
    "    ret, corners_img = cv2.findChessboardCorners(img, (9, 6), None)\n",
    "    \n",
    "    if not ret:\n",
    "        raise ValueError(\"Gittermuster im Bild konnte nicht gefunden werden.\")\n",
    "\n",
    "    return corners_pattern, corners_img\n",
    "\n",
    "def compute_depth_map(corners_pattern, corners_img, baseline_cm, focal_length_mm):\n",
    "    baseline = baseline_cm / 100.0\n",
    "    focal_length_px = (focal_length_mm / 32.0) * 1000\n",
    "\n",
    "    depth_map = np.zeros((corners_img.shape[0], 1), dtype=np.float32)\n",
    "    \n",
    "    disparities = corners_pattern[:,:,0] - corners_img[:,:,0]  # Nur x-Koordinate\n",
    "    for i in range(len(disparities)):\n",
    "        disparity = disparities[i]\n",
    "        if disparity > 0:\n",
    "            depth = (focal_length_px * baseline) / disparity\n",
    "            depth_map[i] = depth\n",
    "\n",
    "    return depth_map\n",
    "\n",
    "# Definiere die Baseline (Abstand zwischen den Kameras in cm) und die Brennweite (in mm)\n",
    "baseline_cm = 7\n",
    "focal_length_mm = 32\n",
    "\n",
    "# Unverzerrte und verzerrte Gitterpunkte finden\n",
    "corners_pattern, corners_imgL = undistort_pattern(imgL, pattern)\n",
    "corners_pattern, corners_imgR = undistort_pattern(imgR, pattern)\n",
    "\n",
    "# Berechnung der Tiefenkarte für linkes Bild\n",
    "depth_map_L = compute_depth_map(corners_pattern, corners_imgL, baseline_cm, focal_length_mm)\n",
    "depth_map_R = compute_depth_map(corners_pattern, corners_imgR, baseline_cm, focal_length_mm)\n",
    "\n",
    "# Zeigen der Tiefenkarte\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(depth_map_L, cmap='plasma')\n",
    "plt.colorbar(label='Tiefe (Meter)')\n",
    "plt.title('Tiefenkarte Links')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(depth_map_R, cmap='plasma')\n",
    "plt.colorbar(label='Tiefe (Meter)')\n",
    "plt.title('Tiefenkarte Rechts')\n",
    "\n",
    "plt.show()"
   ],
   "id": "4279c644c11288d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Einlesen der Bilder\n",
    "imgL = cv2.imread('Utils/lasertestv2-links.png', cv2.IMREAD_GRAYSCALE)\n",
    "imgR = cv2.imread('Utils/lasertestv2-rechts.png', cv2.IMREAD_GRAYSCALE)\n",
    "pattern = cv2.imread('Utils/lasertestv2-links2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Funktion zur Erkennung und Berechnung der Tiefenkarte basierend auf Gitterlinienverzerrung\n",
    "def create_depth_map_from_pattern(img, pattern, baseline_cm, focal_length_mm):\n",
    "    # Find the edges of the pattern\n",
    "    edges_pattern = cv2.Canny(pattern, 50, 150)\n",
    "    edges_img = cv2.Canny(img, 50, 150)\n",
    "\n",
    "    # Hough Line Transform to detect lines in both images\n",
    "    lines_pattern = cv2.HoughLines(edges_pattern, 1, np.pi / 180, 200)\n",
    "    lines_img = cv2.HoughLines(edges_img, 1, np.pi / 180, 200)\n",
    "\n",
    "    # Calculate the disparity of lines between the pattern and the image\n",
    "    baseline = baseline_cm / 100.0\n",
    "    focal_length_px = (focal_length_mm / 32.0) * 1000\n",
    "\n",
    "    depth_map = np.zeros_like(img, dtype=np.float32)\n",
    "\n",
    "    for pattern_line in lines_pattern:\n",
    "        rho_pat, theta_pat = pattern_line[0]\n",
    "        for img_line in lines_img:\n",
    "            rho_img, theta_img = img_line[0]\n",
    "\n",
    "            # Calculate the disparity (simplified as difference in rho, assuming horizontal lines)\n",
    "            disparity = np.abs(rho_pat - rho_img)\n",
    "            if disparity > 0:\n",
    "                depth = (focal_length_px * baseline) / disparity\n",
    "                if 0 <= int(rho_img) < depth_map.shape[0]:\n",
    "                    depth_map[int(rho_img)] = depth\n",
    "\n",
    "    # Normalisieren und Umwandeln zur Visualisierung\n",
    "    depth_map = cv2.normalize(depth_map, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    depth_map = np.uint8(depth_map)\n",
    "\n",
    "    return depth_map\n",
    "\n",
    "# Definiere die Baseline (Abstand zwischen den Kameras in cm) und die Brennweite (in mm)\n",
    "baseline_cm = 7\n",
    "focal_length_mm = 32\n",
    "\n",
    "# Tiefenkarte aus dem Gittermuster erstellen\n",
    "depth_map = create_depth_map_from_pattern(imgL, pattern, baseline_cm, focal_length_mm)\n",
    "\n",
    "# Tiefenkarte anzeigen\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(depth_map, cmap='plasma')\n",
    "plt.colorbar(label='Tiefe (Meter)')\n",
    "plt.title('Tiefenkarte aus projiziertem Gittermuster')\n",
    "plt.show()"
   ],
   "id": "478a9434ce75ba17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Lade die Stereo-Bilder\n",
    "imgL = cv2.imread('Utils/lasertestv2-links.png', cv2.IMREAD_GRAYSCALE)\n",
    "imgR = cv2.imread('Utils/lasertestv2-rechts.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initiere den Stereo-SBM-Algorithmus (Stereo Block Matching)\n",
    "stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "\n",
    "# Berechne die Disparität (Differenz der Pixelkoordinaten zwischen den beiden Bildern)\n",
    "disparity = stereo.compute(imgL, imgR)\n",
    "\n",
    "# Normiere die Disparität zur Visualisierung\n",
    "disparity_normalized = cv2.normalize(disparity, disparity, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "# Erstelle eine Farbkodierte Tiefenkarte (optional)\n",
    "depth_colormap = cv2.applyColorMap(disparity_normalized, cv2.COLORMAP_JET)\n",
    "\n",
    "# Zeige die Ergebnisse\n",
    "plt.subplot(221), plt.imshow(imgL, cmap='gray'), plt.title('Linkes Bild')\n",
    "plt.subplot(222), plt.imshow(imgR, cmap='gray'), plt.title('Rechtes Bild')\n",
    "plt.subplot(223), plt.imshow(disparity, cmap='plasma'), plt.title('Disparitätskarte')\n",
    "plt.subplot(224), plt.imshow(depth_colormap), plt.title('Farbkodierte Tiefenkarte')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Speichere die Ergebnisse\n",
    "cv2.imwrite('disparity_map.png', disparity)\n",
    "cv2.imwrite('depth_colormap.png', depth_colormap)\n"
   ],
   "id": "9e4af353d5f8c04d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_lines(img):\n",
    "    \"\"\"Detect lines using the Hough Transformation.\"\"\"\n",
    "    edges = cv2.Canny(img, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=80, minLineLength=50, maxLineGap=10)\n",
    "    return lines\n",
    "\n",
    "def filter_lines(lines, img_shape):\n",
    "    \"\"\"Filter and sort lines as left and right\"\"\"\n",
    "    left_lines = []\n",
    "    right_lines = []\n",
    "    \n",
    "    center_x = img_shape[1] // 2\n",
    "    \n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        if x1 < center_x and x2 < center_x:\n",
    "            left_lines.append(line[0])\n",
    "        elif x1 > center_x and x2 > center_x:\n",
    "            right_lines.append(line[0])\n",
    "    \n",
    "    # Sort lines by y1 position\n",
    "    left_lines = sorted(left_lines, key=lambda x: min(x[1], x[3]))\n",
    "    right_lines = sorted(right_lines, key=lambda x: min(x[1], x[3]))\n",
    "    \n",
    "    return left_lines, right_lines\n",
    "\n",
    "def plot_lines(img, lines, title):\n",
    "    \"\"\"Plot lines on an image.\"\"\"\n",
    "    img_with_lines = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    for x1, y1, x2, y2 in lines:\n",
    "        cv2.line(img_with_lines, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    plt.imshow(img_with_lines)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def estimate_depth_from_lines(left_lines, right_lines, focal_length, baseline):\n",
    "    \"\"\"Estimate depth from line displacement differences\"\"\"\n",
    "    disparities = []\n",
    "    depths = []\n",
    "    \n",
    "    for (l1, r1), (l2, r2) in zip(left_lines, right_lines):\n",
    "        disparity = np.abs(l1[0] - r1[0])\n",
    "        disparities.append(disparity)\n",
    "        z = (focal_length * baseline) / disparity if disparity != 0 else float('inf')\n",
    "        depths.append(z)\n",
    "    \n",
    "    return depths\n",
    "\n",
    "# Load the stereo images\n",
    "imgL = cv2.imread('Utils/lasertestv2-links.png', cv2.IMREAD_GRAYSCALE)\n",
    "imgR = cv2.imread('Utils/lasertestv2-rechts.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Detect lines using Hough Transform\n",
    "linesL = detect_lines(imgL)\n",
    "linesR = detect_lines(imgR)\n",
    "\n",
    "# Filter and sort lines into left and right\n",
    "left_linesL, right_linesL = filter_lines(linesL, imgL.shape)\n",
    "left_linesR, right_linesR = filter_lines(linesR, imgR.shape)\n",
    "\n",
    "# Using only the first lines from left and right\n",
    "left_lineL = left_linesL[0]\n",
    "right_lineL = right_linesL[0]\n",
    "left_lineR = left_linesR[0]\n",
    "right_lineR = right_linesR[0]\n",
    "\n",
    "# Plot lines for visualization\n",
    "plot_lines(imgL, [left_lineL, right_lineL], \"Linkes Bild with Reference Lines\")\n",
    "plot_lines(imgR, [left_lineR, right_lineR], \"Rechtes Bild with Reference Lines\")\n",
    "\n",
    "# Calculate depths based on first reference and subsequent lines (use more lines if present)\n",
    "focal_length = 3200  # This should be the focal length in pixels\n",
    "baseline = 50  # This is the distance between the two camera centers\n",
    "\n",
    "depths = estimate_depth_from_lines([left_lineL, right_lineL], [left_lineR, right_lineR], focal_length, baseline)\n",
    "\n",
    "print(f\"Estimated Depths: {depths}\")\n",
    "\n",
    "# Generate an image showing the estimated depth for each line\n",
    "depth_image = np.zeros_like(imgL, dtype=np.uint8)\n",
    "depth_values = []\n",
    "\n",
    "for depth, (x1, y1, x2, y2) in zip(depths, [left_lineL, right_lineL]):\n",
    "    depth_values.append(depth)\n",
    "    cv2.line(depth_image, (x1[0], y1), (x2[0], y2), int(depth / 10), 2)  # Assume depths scaled for visualization\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(depth_image, cmap='inferno')\n",
    "plt.title(\"Tiefenkarte basierend auf Linienverzerrung\")\n",
    "plt.colorbar(label='Tiefe (cm)')\n",
    "plt.show()\n",
    "\n",
    "# Display the depth values calculated\n",
    "for i, depth in enumerate(depth_values, start=1):\n",
    "    print(f\"Tiefe der Linie {i}: {depth:.2f} cm\")"
   ],
   "id": "73cd94009d72a41c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
